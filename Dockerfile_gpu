# Use PyTorch image with CUDA support (includes Python 3.11, PyTorch, CUDA)
FROM pytorch/pytorch:2.5.1-cuda12.4-cudnn9-devel

# Avoid interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    sox \
    libsox-dev \
    libsox-fmt-all \
    ffmpeg \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Set Environment Variables for llama-cpp-python CUDA build
ENV CMAKE_ARGS="-DGGML_CUDA=on"
ENV FORCE_CMAKE=1

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt && \
    pip install --no-deps git+https://github.com/rekuenkdr/Qwen3-TTS-streaming.git@97da215 && \
    pip install flash-attn --no-build-isolation

# Copy application code
COPY app.py .
COPY core/ core/
COPY tools/ tools/
COPY utils/ utils/
COPY audio/ audio/

CMD ["python", "app.py"]
