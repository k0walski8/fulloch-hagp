# Use PyTorch image with CUDA support (includes Python 3.11, PyTorch, CUDA)
FROM pytorch/pytorch:2.5.1-cuda12.4-cudnn9-devel

# Avoid interactive prompts
ENV DEBIAN_FRONTEND=noninteractive

# Install system dependencies
RUN apt-get update && apt-get install -y \
    git \
    sox \
    libsox-dev \
    libsox-fmt-all \
    ffmpeg \
    libportaudio2 \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Point HuggingFace cache at the mounted data volume so from_pretrained()
# finds models downloaded by launch.sh into data/models/hub/
ENV HF_HOME=/app/data/models
ENV HF_HUB_OFFLINE=1

# Set Environment Variables for llama-cpp-python CUDA build
ENV CMAKE_ARGS="-DGGML_CUDA=on"
ENV FORCE_CMAKE=1

# Install Python dependencies (Force transformers 4.57.3 for offline Qwen3 ASR to work)
RUN pip install torch torchaudio --index-url https://download.pytorch.org/whl/cu130
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt && \
    pip install --no-deps git+https://github.com/rekuenkdr/Qwen3-TTS-streaming.git@97da215 && \
    pip install flash-attn --no-build-isolation

# Copy application code
COPY app.py .
COPY core/ core/
COPY tools/ tools/
COPY utils/ utils/
COPY audio/ audio/

CMD ["python", "app.py"]
